---
title: 퍼시스턴트 볼륨
tags: 인프라 도서
article_header:
type: cover
---

# 퍼시스턴트 스토리지 사용

---

지금까지 학습한 내용의 스토리지 **볼륨**은 생명주기가 **파드**의 **라이프사이클**과 함깨하기 때문에 일시적이라는 특징이 있다.

하지만, 파드가 **스캐쥴링** 되었을 떄 데이터를 유지하고, 이전의 정보를 필요로 할 때가 있다. 그런경우 **퍼시스턴트 볼륨**을 고려해야 한다.

영구적인 데이터를 허용하는 볼륨을 알아보기 위해 **MongoDB(NOSOQL)**를 **파드**로 생성하고 학습한다.

<br>

## GCE 퍼시스턴트 디스크를 파드 볼륨으로 사용하기

---

현재 **GCE**에 클러스터 노드가 실행 중이기 떄문에 구글 쿠버네티스 엔진에서 사용가능한 **GCE 퍼시스턴트 디스크**를 기반 스토리지 메커니즘으로 사용한다.

<br>

### GCE 퍼시스턴트 디스크 생성하기

---

**GCE** 퍼시스턴트 디스크를 생성하는 것부터 시작한다. 클러스터와 동일한 지역에 생성하여야 하기 때문에 클러스터의 위치를 조회한다.

<br>

````
gcloud container clusters list
````

로 확인가능하다.

<br>

![](https://raw.githubusercontent.com/jickDo/picture/master/Book/K8s_in_action/cp6/cluster_location.png)

위치 **asia-northeast3**이다.

이제 위치를 확인했으니 **mongodb**의 이름으로 **GCE 퍼시스턴트 디스크**를 생성한다.

<br>
<br>

![](https://raw.githubusercontent.com/jickDo/picture/master/Book/K8s_in_action/cp6/gce_persistent_disk.png)

위 명령어를 통해서 **GCE 퍼시스턴트 디스크**를 생성할 수 있다.

<br>

### GCE 퍼시스턴트 디스크를 볼륨으로 사용하기

---

````yaml
apiVersion: v1
kind: Pod
metadata:
  name: mongodb
spec:
  volumes:
    - name: mongodb-data #볼륨의 이름
      gcePersistentDisk: #볼륨의 유형
        pdName: mongodb #여기 이름은 이전의 GCE PD와 일치해야 한다
        fsType: ext4 #리눅스 파일시스템중 하나
  containers:
    - image: mongo
      name: mongodb
      volumeMounts:
        - name: mongodb-data
          mountPath: /data/db
      ports:
        - containerPort: 27017
          protocol: TCP
````

위와같이 **GCE PD**의 이름을 가져다가 사용하고 이것을 볼륨으로 이용하면 된다.

<br>

![](https://raw.githubusercontent.com/jickDo/picture/master/Book/K8s_in_action/cp6/gce_pd_volume.png)

<br>

위와같이 선언하면 사진처럼 외부의 **GCE PD**를 볼륨으로 접근해서 사용하게 된다.

<br>
<br>

현재 환경은 **minikube**를 이용해 진행하고 있기 때문에, **GCE 퍼시스턴트**를 생성할 수 없다.

<br>

### AWS Elastic Block Store 볼륨 사용하기

---

````yaml
apiVersion: v1
kind: Pod
metadata:
  name: mongodb
spec:
  volumes:
    - name: mongodb-data #볼륨의 이름
      awsElasticBlockStore: #볼륨의 유형
        volumeId: <volume name> #여기 이름은 이전의 GCE PD와 일치해야 한다
        fsType: ext4 #리눅스 파일시스템중 하나
  containers:
    - image: mongo
      name: mongodb
      volumeMounts:
        - name: <volume name>
          mountPath: /data/db
      ports:
        - containerPort: 27017
          protocol: TCP

````

이런식으로 **AWS Elastic Block Store**을 볼륨으로 사용할 수도 있다.

또한, **NFS**나 다른 스토리지 기술을 이용해서 만들 수도 있다.

<br>
<br>

## 다른 스토리지 기술 사용하기

---

다른 스토리지 선택사항으로는 **ISCSI** 디스크 리소스를 마운트하기 위한 iscsi,

GlusterFS 마운트를 위한 glusterfs

RADOS 블록 디바이스를 위한 rdb

그 외, flexVolume, cinder, cephfs, flocker, fc등이 있다고 한다.

사용하지 않는다면 몰라도 되지만 쿠버네티스는 이정도로 다양한 스토리지 기술을 지원하고 있다.

여기 까지 왔다면, 이러한 의문이 들 수 있다.

**개발자가 이 모든 것을 알아야 할까?**

**개발자가 파드를 만들때 인프라스트럭처와 관련된 스토리지 세부사항을 처리해야 할까?**

쿠버네티스의 입장에서도 **파드**의 **볼륨**이 실제 기반 인프라스트럭처를 참조한다는 것이 **쿠버네티스**가 추구하는
바가 아니다.

이러한 방식은 파드에 인프라 스트럭처 정보를 포함한다는 것이 특정 클러스터에 밀접하게 연결됨을 의미하고, 이러한 방식은
다른 클러스터에서 동일한 파드의 정의를 사용못한다는 것이다.

<br>
<br>

# 기반 스토리지 기술과 파드 분리

---

쿠버네티스는 애플리케이션과 개발자로 부터 **인프라**를 분리하고, 어디서든 이식 가능한 **환경**을 구축하고, 인프라 세부사항을 **쿠버네티스**에게
위임하는 방식을 원하지만, 이전에 보았던 방식은 그것과 거리가 멀다.

이상적인 쿠버네티스는 **개발자**가 **인프라**의 구조를 몰라도 되며, **파드**가 실행되기 위해 어떤 물리구조가 사용되었는지 몰라도 된다.

이러한 내용은 **인프라 관리자**의 영역이기 때문이다.


<br>
<br>

## 퍼시스턴트 볼륨(pv)와 퍼시스턴트 볼륨 클레임(pvc)

---

조금전에 설명했던 개발자가 **인프라**에 대한 **세부사항**을 숨기기 위해 두가지 리소스가 도입되었는데, **pv**와 **pvc**이다.

<br>

자세한 설명과 플로우는 아래 사진을 통해 확인하겠다.

<br>

![](https://raw.githubusercontent.com/jickDo/picture/master/Book/K8s_in_action/cp6/pv_pvc_flow.png)

<br>

기본적인 플로우는 **인프라 관리자**가 **NFS 나 그와 유사한** 네트워크 스토리지 유형을 설정하고, 이것을 **yaml**파일로 생성해 **쿠버네티스 API서버**에 게시한다.

그 이휴 생성된 **pv**를 참고해, 이번에는 개발자가 **pvc**를 **yaml**파일을 통해 생성하고 게시한다.

**쿠버네티스**는 적정한 크기와 접근 모드의 **PV**를 찾고, **PVC**를 **PV**에 바인딩한다.

마지막으로 이렇게 만들어진 **pvc**를 이용해 사용자(개발자)는 **파드**에 **pvc**를 참조하는 볼륨을 생성한다.

<br>
<br>

## 퍼시스턴트볼륨 생성

---

````yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: mongodb-pv
spec:
  capacity:
    storage: 1Gi # 영속볼륨 사이즈를 지정한다.
  accessModes: # 이 PV는 단일 클라이언트의 읽기/쓰기용(ReadWriteOnce)이나 여러 클라이언트를 위한 읽기 전용(ReadOnlyMany)으로 마운트 된다.
    - ReadWriteOnce
    - ReadOnlyMany
  persistentVolumeReclaimPolicy: Retain # 클레임이 해제된 후 퍼시스턴트 볼륨은 유지돼야 한다.
  gcePersistentDisk: #이전에 생성해둔 GCE 퍼시스턴트 디스크를 기반으로 한다.
    pdName: mongodb
    fsType: ext4
````

> 위와같은 방식으로 **ps**를 생성할 수 있고, 현재 실습환경은 **minikube**이기 때문에 위 형식으로는 생성이 안된다.
 추가적으로, 책에서는 **gce disk**방식말고 **hostPath**로 실습을 권하지만, 현재 **GKE Autopilot**에서 **hostPath**를 사용할 수 없는 문제가 있어 글로만 작성한다.

**PS**를 생성할떄, 관리자는 **쿠버네티스**에게 **용량**이 얼마나 되는지와, 단일 노드나 동시에 다수 노드에 읽기나 쓰기가 가능한지 여부를 알려줘야 한다. 또한

쿠버네티스에게 **ps**가 해제되면 어떠한 동작을 해야 하는지 알려줘야 한다. 여기서는 (persistentVolumeReclaimPolicy)을 사용한다.

마지막으로 **ps** 볼륨을 지원하는 실제 스토리지의 유형이나, 위치, 그 밖의 속성 정보를 지정해야 한다.

**yaml**파일을 마지막은 이전의 **퍼시스턴트 디스크**를 **직접 참조**를 했던 방식과 비슷한것을 확인할 수 있다.

> 퍼시스턴트 볼륨은 특정 네임스페이스에 속하지 않는, 노드와 같은 클러스터의 수준 리소스다.

<br>
<br>

![](https://raw.githubusercontent.com/jickDo/picture/master/Book/K8s_in_action/cp6/ps_high_level.png)

<br>

> 퍼시스턴트 클레임은 네임스페이스에 속한다.

<br>
<br>

## pvc을 생성을 통한 pv 요청

---

이전까지 진행했다면 이제 **인프라 관리자**의 영역의 수준이고 지금부터 다루게 될 **pvc**는 **개발자**의 수준에서 관리할 수 있는 부분이다.

**pvc**을 **파드** 생성과 함깨 선언해도 되지만, 그렇게 된다면 **파드**의 생명주기와 동일하게 생성되고 지워지는 문제가 있을 수 있다.

그렇기 때문에 **파드**생성에 앞서, **pvc**를 독립적으로 생성하고 관리하여 재사용성을 높일 것이다.

<br>
<br>

### pvc 생성하기

---

<br>

````yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: mongodb-pvc # 파드에서 볼륨요청시 이 이름사용
spec:
  resources:
    requests:
      storage: 1Gi #1GiB의 스토리지를 요구
  accessModes:
    - ReadWriteOnce #단일 클라이언트를 지원하는 스토리지 (읽기 쓰기 모두 가능)
  storageClassName: "" # 이후 동적프로바이딩에서 설명
````

위 **pvc**를 생성하게 되면, 생성되자마자 쿠버네티스는 적절한 **pv**를 찾고 클레임에 바인딩한다.

당연히 **pv**는 생성된 클레임에 요청에 응할만큼 충분한 용량이 있어야 하며, **접근모드** 또한 클레임이 요청한
접근모드를, **pv**는 가지고있어야 한다.

<br>
<br>

### pvc 조회하기

---

````
kubectl get pvc
````

를통해서 조회가능하다
아래는 pv를 조회할수 있다.

````
kubectl get pv
````

를통해서 조회가능하다

조회되는 클레임에 접근모드가 나오는데 **약어**로 출력된다.

1. RWO(ReadWriteOnce): 단일 노드만이 읽기/쓰기용으로 볼륨을 마운트 할 수 있다.
2. ROX(ReadOnlyMany): 다수 노드가 읽기용으로 볼륨을 마운트 할 수 있다.
3. RWX(ReadWriteMany): 다수 노드가 읽기/쓰기용으로 볼륨을 마운트 할 수 있다.

> 여기서 나오는 단일, 다수는 **파드**의 수가 아닌, 접근 가능한 **워커 노드**의 수이다.

<br>
<br>

## 파드에서 퍼시스턴트 볼륨 클레임 사용하기

---

````yaml
apiVersion: v1
kind: Pod
metadata:
  name: mongodb
spec:
  containers:
    - image: mongo
      name: mongodb
      volumeMounts:
        - name: mongodb-data
          mountPath: /data/db
      ports:
        - containerPort: 27017
          protocol: TCP
  volumes:
    - name: mongodb-data
      persistentVolumeClaim:
        claimName: mongodb-pvc # 파드 볼륨에서 이름으로 pvc를 참조한다.
````

위 처럼 생성해 둔 **pvc**를 파드 생성 시 사용할 수 있다.

<br>
<br>

## pv, pvc 사용 장점

---

![](https://raw.githubusercontent.com/jickDo/picture/master/Book/K8s_in_action/cp6/pv_pvc_merit.png)

위 사진을 통해서 설명하면, 첫번쨰 사진은 이전에 사용한 볼륨에서 직접적으로 **GCE 디스크**에 접근하는 방법이고, 두번째 사진은

**pv**와 **pvc** 선언을 통해 접근하는 방식이다.

두번쨰 방식의 장점은 **인프라 관리자**와 **개발자**를 분리하여, **개발자**에게 간접적인 **스토리지**를 가져오는 방식을 제공한다는 것이다.

추가적인 플로우가 생기는 방식은 맞지만, **개발자**에게 **실제 스토리지** 기술을 알게 하는것보다 간단하다.

그리고 인프라 스트럭쳐에 관한 정보를 **파드**에서 선언하는 것이 아니기 떄문에 다른 쿠버네티스 클러스터 에서도 재사용 가능하다.

<br>

## 재 사용성

---

만약에 **파드**와 **pvc**를 삭제하고 다시 만든다면 어떻게 될까?

결과는, **pvc**가 생성되지 못하고, **pending** 상태로 남아있다.

이유는 **파드**와 **pvc**는 삭제되었지만, **pv**는 이전의 정보를 가지고 있고, 이 상태에서 **pvc**가 바인딩되면

이전의 정보를 읽어오기 떄문이다.

<br>
<br>

### pv를 수동으로 클레임하기

---

쿠버네티스에 **persistentVolumeClaimPolicy**를 **retain**으로 설정하면 **pv**는 클레임이 해제되어도
볼륨과 컨텐츠를 유지한다. 즉 **pv**를 수동으로 재사용하려면 직접 **pv** 리소스를 제거해야 한다.

<br>
<br>

### pv를 자동으로 클레임하기

---

정책을 **Delete**나, **Recycle**로 설정하면 자동으로 클레임을 할 수 있다.

**Recycle**은 볼륨의 콘텐츠를 삭제하고 볼륨이 다시 클레임될 수 있도록 볼륨을 사용가능 하게 만들고, **Delete**는 기반 스토리지를 삭제한다.

<br>
<br>

# 퍼시스턴트볼륨의 동적 프로비저닝

---

현재는 클러스터 관리자는 실제 스토리지를 미리 프로비저닝 해둬야 한다. 다행히도 쿠버네티스는 퍼시스턴트 볼륨의 동적 프로비저닝을 통해
이 작업을 자동으로 수행할 수 있다.

**클러스터 관리자가** **pv**을 생성하는 대신 **pv** 프로비저너를 배포하고 사용자가 선택 가능한 **pv**의 타입을 하나 이상의 **스토리지 클래스**
오브젝트로 정의할 수 있다.

사용자가 **pvc**에서 스토리지 클래스를 참조하면 **프로비저너**가 퍼시스턴트 스토리지를 프로비저닝할때 이를 처리한다.

> 스토리지 클래스토 네임스페이스에 속하지 않는다.

<br>

## 스토리지 클래스 리소스를 통한 사용 가능한 스토리지 유형 정의하기

---

사용자가 **pvc**를 생성하면 결과적으로 새로운 **pv**가 필요하기 때문에 관리자는 하나 혹은 그 이상의 스토리지 클래스 리소스를 생성해야 한다.

<br>

````yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: fast
provisioner: kubernetes.io/gce-pd # pv 프로비저닝을 위해 사용되는 볼륨 플러그인
parameters:
  type: pd-ssd
  zone: europe-west1-b # 이런 파라미터가 프로비저너로 전달된다.
````

**스토리지 클래스** 리소스는 **pvc**에서 스토리지클래스에 요청할 때 어떤 프로비저너가 **pv**을 프로비저닝 하는데 사용돼야 할지를 지정한다.

스토리지 클래스에 정의된 파라미터들은 프로비저너에 전달되며, 파라미터는 각 프로비저너 플러그인 마다 다르다.

<br>
<br>

## pvc에서 스토리지 클래스 요청하기

---

스토리지 클래스 리소스가 생성되면 사용자는 **pvc**의 이름에 스토리지 클래스를 참조할 수 있다.

````yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: mongodb-pvc
spec:
  storageClassName: fast # PVC는 사용자 정의 스토리지 클래스를 요청한다.
  resources:
    requests:
      storage: 100Mi
    accessModes:
      - ReadWriteOnce
````

크기와 접근 모드 외에도 **pvc**에 사용할 스토리지 클래스를 지정해야 한다.
클레임을 생성하면 fast 스토리지 클래스 리소스에 참조된 프로비저너가 **pv**을 생성한다.

<br>
<br>

### 퍼시스턴트볼륨 동적 프로비저닝의 전체 그림 이해하기

---

![](https://raw.githubusercontent.com/jickDo/picture/master/Book/K8s_in_action/cp6/whole_picture.png)




